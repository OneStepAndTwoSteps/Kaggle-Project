{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center> Predictive Analysis - Porto Seguro’s Safe Driver Prediction | Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center> I. Importation & Missing Value Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.offline as py     # 绘图的函数\n",
    "\n",
    "\n",
    "import plotly.graph_objs as go              # 可用于绘制不同图型，如 go.bar()\n",
    "import plotly.express as px                 # 可用于绘制不同图型，如 px.bar()\n",
    "from plotly.subplots import make_subplots   # 创建子图\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)    #THIS LINE IS MOST IMPORTANT AS THIS WILL DISPLAY PLOT ON \n",
    "#NOTEBOOK WHILE KERNEL IS RUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "2  13       0          5              4          9              1   \n",
       "3  16       0          0              1          2              0   \n",
       "4  17       0          0              2          0              1   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ...  \\\n",
       "0              0              0              1              0  ...   \n",
       "1              0              0              0              1  ...   \n",
       "2              0              0              0              1  ...   \n",
       "3              0              1              0              0  ...   \n",
       "4              0              1              0              0  ...   \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           5           8               0   \n",
       "1           3           1           1           9               0   \n",
       "2           4           2           7           7               0   \n",
       "3           2           2           4           9               0   \n",
       "4           3           1           1           3               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "2               1               1               0               1   \n",
       "3               0               0               0               0   \n",
       "4               0               0               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate missing values by column# Funct \n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "\n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "\n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "\n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "\n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "\n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "            \" columns that have missing values.\")\n",
    "\n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy = train\n",
    "train_copy = train_copy.replace(-1, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 59 columns.\n",
      "There are 13 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ps_car_03_cat</th>\n",
       "      <td>411231</td>\n",
       "      <td>69.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_05_cat</th>\n",
       "      <td>266551</td>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_reg_03</th>\n",
       "      <td>107772</td>\n",
       "      <td>18.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_14</th>\n",
       "      <td>42620</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_07_cat</th>\n",
       "      <td>11489</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <td>5809</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_09_cat</th>\n",
       "      <td>569</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <td>216</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_01_cat</th>\n",
       "      <td>107</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_02_cat</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_11</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Missing Values  % of Total Values\n",
       "ps_car_03_cat          411231               69.1\n",
       "ps_car_05_cat          266551               44.8\n",
       "ps_reg_03              107772               18.1\n",
       "ps_car_14               42620                7.2\n",
       "ps_car_07_cat           11489                1.9\n",
       "ps_ind_05_cat            5809                1.0\n",
       "ps_car_09_cat             569                0.1\n",
       "ps_ind_02_cat             216                0.0\n",
       "ps_car_01_cat             107                0.0\n",
       "ps_ind_04_cat              83                0.0\n",
       "ps_car_02_cat               5                0.0\n",
       "ps_car_11                   5                0.0\n",
       "ps_car_12                   1                0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values statistics\n",
    "missing_values = missing_values_table(train_copy)  # train_copy 是一个 dataframe\n",
    "missing_values.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出 `ps_car_03_cat` 和 `ps_car_05_cat` 所占缺失值比例很高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>II. Data Cleaning & Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_counts = train.target.value_counts()\n",
    "# train_counts = pd.DataFrame(train_counts)\n",
    "\n",
    "# fig = px.bar(train_counts,x=train_counts.index,y='target',barmode='group',color='target')\n",
    "# fig.update_traces(textposition='outside')\n",
    "# fig.update_layout(template='seaborn',title='target (counts)')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目标变量检测\n",
    "\n",
    "对于分类变量我们需要进行目标变量检测，如果数据存在严重的不平衡，预测得出的结论往往也是有偏的，即分类结果会偏向于较多观测的类。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = train.target.value_counts()\n",
    "train_counts = pd.DataFrame(train_counts)\n",
    "\n",
    "fig = px.bar(train_counts,x=train_counts.index,y='target',barmode='group',color='target',text='target') # text 可以标上数值\n",
    "fig.update_traces(textposition='outside')\n",
    "fig.update_layout(yaxis_title='counts',xaxis_title='target',template='seaborn',title='target (counts)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二进制数据检测 `bin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_col = [col for col in train.columns if '_bin' in col]\n",
    "zero_list = []\n",
    "one_list = []\n",
    "for col in bin_col:\n",
    "    zero_list.append((train[col]==0).sum())\n",
    "    one_list.append((train[col]==1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = go.Bar(\n",
    "    x=bin_col,\n",
    "    y=zero_list ,\n",
    "    name='Zero count'\n",
    ")\n",
    "trace2 = go.Bar(\n",
    "    x=bin_col,\n",
    "    y=one_list,\n",
    "    name='One count'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    barmode='stack',\n",
    "    title='Count of 1 and 0 in binary variables'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们能看到，对于`10_bin` `11_bin` `12_bin` `13_bin` 基本上全是目标值都为 0，那么我们可以初步判断这几个特征可能对我们的目标值预测起不了作用，等一下我们也可以再进一步的去验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据不平衡\n",
    "\n",
    "可以发现标签之前存在不平衡的状态，如果数据存在严重的不平衡，预测得出的结论往往也是有偏的，即分类结果会偏向于较多观测的类。\n",
    "\n",
    "比如我们使用准确率来进行模型的评估，即使我们全部预测成 `target == 0`，那么也有很高的准确率: `573518/(573518+21694)=0.96`。\n",
    "\n",
    "所以对于分类不平衡的数据，我们可以进行如下操作：\n",
    "\n",
    "### 欠采样：\n",
    "\n",
    "随机欠采样（下采样）的目标是通过随机地消除占多数的类的样本来平衡类分布；直到多数类和少数类的实例实现平衡，目标才算达成。\n",
    "\n",
    "* `随机欠采样（下采样）`的目标是通过随机地消除占多数的类的样本来平衡类分布；直到多数类和少数类的实例实现平衡，目标才算达成。\n",
    "\n",
    "* `随机下采样的优点：`\n",
    "    \n",
    "    它可以提升运行时间；并且当训练数据集很大时，可以通过减少样本数量来解决存储问题。\n",
    "\n",
    "* `随机下采样的缺点：`\n",
    "    \n",
    "    它会丢弃对构建规则分类器很重要的有价值的潜在信息。\n",
    "\n",
    "    被随机欠采样选取的样本可能具有偏差。它不能准确代表大多数。从而在实际的测试数据集上得到不精确的结果。果。\n",
    "\n",
    "\n",
    "### 过采样\n",
    "\n",
    "\n",
    "* `随机过采样` 通过随机复制少数类来增加其中的实例数量，从而可增加样本中少数类的代表性。\n",
    "\n",
    "* `随机过采样的优点：`\n",
    "\n",
    "    与欠采样不同，这种方法不会带来信息损失。\n",
    "\n",
    "    表现优于欠采样。\n",
    "\n",
    "* `随机过采样的缺点：`\n",
    "    \n",
    "    由于复制少数类事件，它加大了过拟合的可能性。\n",
    "    \n",
    "\n",
    "本 notebook 将采用 SMOTE 来进行过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不进行采样，直接进行模型训练和预测查看模型质量\n",
    "\n",
    "* 通过对比准确度和召回率\n",
    "    \n",
    "* 通过绘制混淆矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、对比准确度和召回率\n",
    "\n",
    "可以看到，即使你的准确率非常高，但是召回率却非常低    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train['target']\n",
    "train_feature = train.drop(columns='target')\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(train_feature,train_target,test_size= 0.2,random_state=10)\n",
    "\n",
    "# model = XGBClassifier(n_estimators=1000)\n",
    "model = XGBClassifier()\n",
    "\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "recall = recall_score(y_test,y_pred)\n",
    "\n",
    "print('Accuracy: {:.3f}'.format(acc* 100.0))\n",
    "print('recall: {:.3f}'.format(recall* 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、绘制混淆矩阵\n",
    "\n",
    "混淆矩阵用法示例，用于评估数据集上分类器输出的质量。 对角线元素表示预测标签等于真实标签的点数，而非对角线元素则是分类器未正确标记的元素。 混淆矩阵的对角线值越高，表示对数越多越好。混淆矩阵用法示例，用于评估数据集上分类器输出的质量。 对角线元素表示预测标签等于真实标签的点数，而非对角线元素则是分类器未正确标记的元素。 混淆矩阵的对角线值越高，表示对数越多越好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                                normalize=False,\n",
    "                                title='Confusion matrix',\n",
    "                                cmap=plt.cm.Blues):\n",
    "        \"\"\"\n",
    "            此函数打印并绘制混淆矩阵。\n",
    "            可以通过设置“ normalize = True”来应用归一化。\n",
    "        \"\"\"\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print(\"Normalized confusion matrix\")\n",
    "        else:\n",
    "            print('Confusion matrix, without normalization')\n",
    "\n",
    "        print(cm)\n",
    "\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, cm[i, j],\n",
    "                        horizontalalignment=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['target_0','target_1'] # 顺序别搞错\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm,classes)\n",
    "plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm,classes,normalize=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 SMOTE 进行过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看2D数据的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义绘图函数\n",
    "def plot_2d_space(X, y, label='Classes'):   \n",
    "            colors = ['#1F77B4', '#FF7F0E']\n",
    "            markers = ['o', 's']\n",
    "            for l, c, m in zip(np.unique(y), colors, markers):\n",
    "                plt.scatter(\n",
    "                    X[y==l, 0],\n",
    "                    X[y==l, 1],\n",
    "                    c=c, label=l, marker=m\n",
    "                )\n",
    "            plt.title(label)\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.show()\n",
    "            \n",
    "print(\"label0: \",len(x_train[y_train==0]))\n",
    "print(\"label1: \",len(x_train[y_train==1]))\n",
    "\n",
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(x_train)\n",
    "\n",
    "# `2、`如果数据存在多维特征可使用PCA来降维，使其能在2D图中展示\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "plot_2d_space(X, y_train, 'Imbalanced dataset (2 PCA components)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler=SMOTE(random_state=0)\n",
    "# 开始人工合成数据\n",
    "os_features,os_labels=oversampler.fit_sample(x_train,y_train)\n",
    "\n",
    "# 查看生成结果\n",
    "print(\"label1: \",len(os_labels[os_labels==1]))\n",
    "print(\"label0: \",len(os_labels[os_labels==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler=SMOTE(random_state=0)\n",
    "# 开始人工合成数据\n",
    "os_features_test,os_labels_test=oversampler.fit_sample(x_test,y_test)\n",
    "\n",
    "# 查看生成结果\n",
    "print(\"label1: \",len(os_labels_test[os_labels_test==1]))\n",
    "print(\"label0: \",len(os_labels_test[os_labels_test==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(os_features)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "plot_2d_space(X, os_labels, 'Imbalanced dataset (2 PCA components)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征相关性检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、特征和目标特征之间的相关性检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_os_features = os_features.copy()\n",
    "new_os_features['target'] = os_labels\n",
    "\n",
    "# Find correlations with the target and sort\n",
    "corrs = new_os_features.corr()['target'].sort_values(ascending=False)\n",
    "correlations = pd.DataFrame(corrs)\n",
    "\n",
    "# Display correlations\n",
    "print('Most Positive Correlations:\\n')\n",
    "correlations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Most Negative Correlations:\\n')\n",
    "correlations.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations.loc[correlations.index.isin(['ps_ind_10_bin','ps_ind_11_bin','ps_ind_12_bin','ps_ind_13_bin'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(corrs).sort_values(ascending=False).tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看出 在 `bin` 类型的特征中 `ps_ind_10_bin`,`ps_ind_11_bin`,`ps_ind_12_bin`,`ps_ind_13_bin` 确实是影响力最低的特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、特征与特征之间进行相关性检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = os_features.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、删除共线特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置阈值\n",
    "threshold = 0.8\n",
    "\n",
    "# 创建一个空字典以容纳相关变量\n",
    "above_threshold_vars = {}\n",
    "\n",
    "# 对于每一列，记录index行中的那个值高于阈值的变量\n",
    "for col in corrs:\n",
    "    above_threshold_vars[col] = list(corrs.index[corrs[col] > threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above_threshold_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 跟踪要删除的列和已检查的列\n",
    "cols_to_remove = []\n",
    "cols_seen = []\n",
    "cols_to_remove_pair = []\n",
    "\n",
    "# 遍历列和相关列\n",
    "for key, value in above_threshold_vars.items():\n",
    "    # 跟踪已检查的列\n",
    "    cols_seen.append(key)\n",
    "    for x in value:\n",
    "        if x == key:\n",
    "            next\n",
    "        else:\n",
    "            # 如果存在高相关的特征，只保留一个\n",
    "            if x not in cols_seen:                  # 如果该特征在之前的 key 数据中没有出现过。\n",
    "                cols_to_remove.append(x)            # 存在高度相关，将高度相关的特征放入 cols_to_remove 中。\n",
    "                cols_to_remove_pair.append(key)     # cols_to_remove 和 cols_to_remove_pair 得到的结果一致。\n",
    "\n",
    "cols_to_remove = list(set(cols_to_remove))\n",
    "print('Number of columns to remove: ', len(cols_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corrs_removed = os_features.drop(columns = cols_to_remove)\n",
    "test_corrs_removed = os_features_test.drop(columns = cols_to_remove)\n",
    "\n",
    "print('Training Corrs Removed Shape: ', train_corrs_removed.shape)\n",
    "print('Testing Corrs Removed Shape: ', test_corrs_removed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corrs_removed.to_csv('train_corrs_removed.csv', index = False)\n",
    "test_corrs_removed.to_csv('test_corrs_removed.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>III. ML Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier 训练数据\n",
    "\n",
    "接下来我们将：\n",
    "\n",
    "* 1、使用 RandomForestClassifier 来进行训练数据\n",
    "\n",
    "* 2、绘制特征的重要性图\n",
    "\n",
    "* 3、并且进一步进行特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_features.drop(['id'],axis=1,inplace=True)\n",
    "os_features_test.drop(['id'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "rdf_clf = RandomForestClassifier(n_estimators=150, max_depth=8, min_samples_leaf=4, max_features=0.2, n_jobs=-1, random_state=0)\n",
    "rdf_clf.fit(os_features, os_labels)\n",
    "features = os_features.columns.values\n",
    "print(\"----- Training Done -----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier feature importances Scatter plot \n",
    "\n",
    "def rdf_feature_importances(model):\n",
    "    trace = go.Scatter(\n",
    "        y = model.feature_importances_,\n",
    "        x = features,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            sizemode = 'diameter',\n",
    "            sizeref = 1,\n",
    "            size = 13,\n",
    "            #size= model.feature_importances_,\n",
    "            #color = np.random.randn(500), #set color equal to a variable\n",
    "            color = model.feature_importances_,\n",
    "            colorscale='Portland',\n",
    "            showscale=True\n",
    "        ),\n",
    "        text = features\n",
    "    )\n",
    "    data = [trace]\n",
    "\n",
    "    layout= go.Layout(\n",
    "        autosize= True,\n",
    "        title= 'Random Forest Feature Importance',\n",
    "        hovermode= 'closest',\n",
    "         xaxis= dict(\n",
    "             ticklen= 5,\n",
    "             showgrid=False,\n",
    "            zeroline=False,\n",
    "            showline=False\n",
    "         ),\n",
    "        yaxis=dict(\n",
    "            title= 'Feature Importance',\n",
    "            showgrid=False,\n",
    "            zeroline=False,\n",
    "            ticklen= 5,\n",
    "            gridwidth= 2\n",
    "        ),\n",
    "        showlegend= False\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.show()\n",
    "\n",
    "rdf_feature_importances(model=rdf_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更近一步，我们还能通过绘制柱状图(横)来对特征重要性进行效果展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = (list(x) for x in zip(*sorted(zip(rdf_clf.feature_importances_, features), \n",
    "                                                            reverse = False)))\n",
    "trace2 = go.Bar(\n",
    "    x=x ,\n",
    "    y=y,\n",
    "    marker=dict(\n",
    "        color=x,\n",
    "        colorscale = 'Viridis',\n",
    "        reversescale = True\n",
    "    ),\n",
    "    name='Random Forest Feature importance',\n",
    "    orientation='h',\n",
    ")\n",
    "\n",
    "layout = dict(\n",
    "    title='Barplot of Feature importances',\n",
    "     width = 900, height = 2000,\n",
    "    yaxis=dict(\n",
    "        showgrid=False,\n",
    "        showline=False,\n",
    "        showticklabels=True,\n",
    "#         domain=[0, 0.85],\n",
    "    ))\n",
    "\n",
    "fig1 = go.Figure(data=[trace2])\n",
    "fig1['layout'].update(layout)\n",
    "py.iplot(fig1, filename='plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rdf_clf.predict(os_features_test)\n",
    "\n",
    "acc = accuracy_score(os_labels_test,y_pred)\n",
    "recall = recall_score(os_labels_test,y_pred)\n",
    "\n",
    "print('Accuracy: {:.3f}'.format(acc* 100.0))\n",
    "print('recall: {:.3f}'.format(recall* 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "\n",
    "\n",
    "model.fit(os_features,os_labels)\n",
    "y_pred = model.predict(os_features_test)\n",
    "\n",
    "acc = accuracy_score(os_labels_test,y_pred)\n",
    "recall = recall_score(os_labels_test,y_pred)\n",
    "\n",
    "print('Accuracy: {:.3f}'.format(acc* 100.0))\n",
    "print('recall: {:.3f}'.format(recall* 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看出相比于之前的不平衡数据，过采样后的数据，召回率得到了明显的上升"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对数据进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = test.drop(columns='id')  \n",
    "test_ids = test['id']\n",
    "new_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选出两个数据中共同拥有的列，不共有的列过滤出去\n",
    "# app_train, app_test = os_features.align(new_test, join = 'inner', axis = 1)\n",
    "\n",
    "\n",
    "# print('Training Features shape: ', app_train.shape)\n",
    "# print('Testing Features shape: ', app_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机森林预测结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = rdf_clf.predict(new_test)\n",
    "\n",
    "submission = pd.DataFrame({'id': test_ids, 'target': test_predictions})\n",
    "submission.to_csv('RandomForestClassifier_predict_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost 预测结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(new_test)\n",
    "\n",
    "submission = pd.DataFrame({'id': test_ids, 'target': test_predictions})\n",
    "submission.to_csv('XGBoost_predict_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征选择"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
